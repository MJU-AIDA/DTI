{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0e8c57-5c6e-441c-9797-6abad30f2eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max38744/.conda/envs/moon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from generating_feature import generating_pro_feature, generating_drug_feature, concat_feature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "train_pro_table = generating_pro_feature(pd.read_csv(\"Davis_train.csv\"))\n",
    "\n",
    "train_drug_table = generating_drug_feature(pd.read_csv(\"Davis_train.csv\"))\n",
    "\n",
    "train_merge_on = concat_feature(train_drug_table, train_pro_table)\n",
    "\n",
    "val_pro_table = generating_pro_feature(pd.read_csv(\"Davis_val.csv\"))\n",
    "\n",
    "val_drug_table = generating_drug_feature(pd.read_csv(\"Davis_val.csv\"))\n",
    "\n",
    "val_merge_on = concat_feature(val_drug_table,val_pro_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fa0b3-cbf5-4a55-8625-7cd28c531c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/max38744/moon_project/tester/drugbank/train_baseline_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5436c43-ce4d-4b66-84c9-5834170c0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def my_SVM(df_train , df_val , d_col, p_col, r_col):\n",
    "    # Train\n",
    "    train_p_feat = pd.DataFrame(df_train[d_col].tolist())\n",
    "    train_d_feat = pd.DataFrame(df_train[p_col].tolist())\n",
    "    \n",
    "    val_p_feat = pd.DataFrame(df_val[d_col].tolist())\n",
    "    val_d_feat = pd.DataFrame(df_val[p_col].tolist())\n",
    "    \n",
    "    \n",
    "    #print(pd.concat([p_feat, d_feat], axis = 1))\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    clf.fit(pd.concat([train_p_feat, train_d_feat], axis = 1), df_train[r_col])\n",
    "    \n",
    "    # Evaluation\n",
    "    pred_rels_train = clf.predict(pd.concat([train_p_feat, train_d_feat], axis = 1))\n",
    "    accuracy_train = accuracy_score(df_train[r_col], pred_rels_train)\n",
    "    f1score_train = f1_score(df_train[r_col], pred_rels_train)\n",
    "    \n",
    "    pred_rels_val = clf.predict(pd.concat([val_p_feat, val_d_feat], axis = 1))\n",
    "    accuracy_val = accuracy_score(df_val[r_col], pred_rels_val)\n",
    "    f1score_val = f1_score(df_val[r_col], pred_rels_val)\n",
    "    \n",
    "    print(\"Validation :\",\"Accuracy:\", accuracy_val, \"F1-score\", f1score_val)\n",
    "    \n",
    "    print(\"Train :\", \"Accuracy:\", accuracy_train, \"F1-score\", f1score_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97af92d8-811d-431e-bd0d-89334499e196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Target_ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Y</th>\n",
       "      <th>Morgan_Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126565</td>\n",
       "      <td>CC12OC(CC1(O)CO)n1c3ccccc3c3c4c(c5c6ccccc6n2c5...</td>\n",
       "      <td>DYRK1A</td>\n",
       "      <td>MHTGGETSACKPSSVRLAPSFSFHAAGLQMAGQMPHSHQYSDRRQP...</td>\n",
       "      <td>1</td>\n",
       "      <td>['0', '0', '0', '0', '1', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>11234052</td>\n",
       "      <td>Cc1cc2c(F)c(Oc3ncnn4cc(OCC(C)O)c(C)c34)ccc2[nH]1</td>\n",
       "      <td>PIK3CA(Q546K)</td>\n",
       "      <td>TMPPRPSSGELWGIHLMPPRILVECLLPNGMIVTLECLREATLITI...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '1', '0', '1', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>447077</td>\n",
       "      <td>CSc1cccc(Nc2ncc3cc(-c4c(Cl)cccc4Cl)c(=O)n(C)c3...</td>\n",
       "      <td>MKNK1</td>\n",
       "      <td>MVSSQKLEKPIEMGSSEPLPIADGDRRRKKKRRGRATDSLPGKFED...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>10427712</td>\n",
       "      <td>Nc1nc(N)c2nc(-c3cccc(O)c3)c(-c3cccc(O)c3)nc2n1</td>\n",
       "      <td>PRKCD</td>\n",
       "      <td>MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>3062316</td>\n",
       "      <td>Cc1nc(Nc2ncc(C(=O)Nc3c(C)cccc3Cl)s2)cc(N2CCN(C...</td>\n",
       "      <td>SBK1</td>\n",
       "      <td>MSVGCPEPEPPRSLTCCGPGTAPGPGAGVPLLTEDMQALTLRTLAA...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>11717001</td>\n",
       "      <td>OCCn1cc(-c2ccc3c(c2)CCC3=NO)c(-c2ccncc2)n1</td>\n",
       "      <td>RAF1</td>\n",
       "      <td>MEHIQGAWKTISNGFGFKDAVFDGSSCISPTIVQQFGYQRRASDDG...</td>\n",
       "      <td>1</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>2516</td>\n",
       "      <td>16722836</td>\n",
       "      <td>Cc1cnc(Nc2ccc(OCCN3CCCC3)cc2)nc1Nc1cccc(S(=O)(...</td>\n",
       "      <td>DCAMKL3</td>\n",
       "      <td>MGKEPLTLKSIQVAVEELYPNKARALTLAQHSRAPSPRLRSRLFSK...</td>\n",
       "      <td>1</td>\n",
       "      <td>['0', '0', '0', '0', '1', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>2538</td>\n",
       "      <td>11712649</td>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>CDK2</td>\n",
       "      <td>MENFQKVEKIGEGTYGVVYKARNKLTGEVVALKKIRLDTETEGVPS...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '0', '0', '0', '0', '1', '0', '0', '1', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2551</td>\n",
       "      <td>44259</td>\n",
       "      <td>CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6ccccc6n2...</td>\n",
       "      <td>CLK4</td>\n",
       "      <td>MRHSKRTHCPDWDSRESWGHESYRGSHKRKRRSHSSTQENRHCKPH...</td>\n",
       "      <td>1</td>\n",
       "      <td>['0', '0', '0', '0', '1', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2575</td>\n",
       "      <td>644241</td>\n",
       "      <td>Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)...</td>\n",
       "      <td>SIK</td>\n",
       "      <td>MVIMSEFSADPAGQGQGQQKPLRVGFYDIERTLGKGNFAVVKLARH...</td>\n",
       "      <td>0</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   Drug_ID                                               Drug  \\\n",
       "1              1    126565  CC12OC(CC1(O)CO)n1c3ccccc3c3c4c(c5c6ccccc6n2c5...   \n",
       "10            10  11234052   Cc1cc2c(F)c(Oc3ncnn4cc(OCC(C)O)c(C)c34)ccc2[nH]1   \n",
       "11            11    447077  CSc1cccc(Nc2ncc3cc(-c4c(Cl)cccc4Cl)c(=O)n(C)c3...   \n",
       "15            15  10427712     Nc1nc(N)c2nc(-c3cccc(O)c3)c(-c3cccc(O)c3)nc2n1   \n",
       "27            27   3062316  Cc1nc(Nc2ncc(C(=O)Nc3c(C)cccc3Cl)s2)cc(N2CCN(C...   \n",
       "...          ...       ...                                                ...   \n",
       "2499        2499  11717001         OCCn1cc(-c2ccc3c(c2)CCC3=NO)c(-c2ccncc2)n1   \n",
       "2516        2516  16722836  Cc1cnc(Nc2ccc(OCCN3CCCC3)cc2)nc1Nc1cccc(S(=O)(...   \n",
       "2538        2538  11712649  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...   \n",
       "2551        2551     44259  CNC1CC2OC(C)(C1OC)n1c3ccccc3c3c4c(c5c6ccccc6n2...   \n",
       "2575        2575    644241  Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)...   \n",
       "\n",
       "          Target_ID                                             Target  Y  \\\n",
       "1            DYRK1A  MHTGGETSACKPSSVRLAPSFSFHAAGLQMAGQMPHSHQYSDRRQP...  1   \n",
       "10    PIK3CA(Q546K)  TMPPRPSSGELWGIHLMPPRILVECLLPNGMIVTLECLREATLITI...  0   \n",
       "11            MKNK1  MVSSQKLEKPIEMGSSEPLPIADGDRRRKKKRRGRATDSLPGKFED...  0   \n",
       "15            PRKCD  MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...  0   \n",
       "27             SBK1  MSVGCPEPEPPRSLTCCGPGTAPGPGAGVPLLTEDMQALTLRTLAA...  0   \n",
       "...             ...                                                ... ..   \n",
       "2499           RAF1  MEHIQGAWKTISNGFGFKDAVFDGSSCISPTIVQQFGYQRRASDDG...  1   \n",
       "2516        DCAMKL3  MGKEPLTLKSIQVAVEELYPNKARALTLAQHSRAPSPRLRSRLFSK...  1   \n",
       "2538           CDK2  MENFQKVEKIGEGTYGVVYKARNKLTGEVVALKKIRLDTETEGVPS...  0   \n",
       "2551           CLK4  MRHSKRTHCPDWDSRESWGHESYRGSHKRKRRSHSSTQENRHCKPH...  1   \n",
       "2575            SIK  MVIMSEFSADPAGQGQGQQKPLRVGFYDIERTLGKGNFAVVKLARH...  0   \n",
       "\n",
       "                                        Morgan_Features  \n",
       "1     ['0', '0', '0', '0', '1', '0', '0', '0', '0', ...  \n",
       "10    ['0', '1', '0', '1', '0', '0', '0', '0', '0', ...  \n",
       "11    ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...  \n",
       "15    ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...  \n",
       "27    ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...  \n",
       "...                                                 ...  \n",
       "2499  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...  \n",
       "2516  ['0', '0', '0', '0', '1', '0', '0', '0', '0', ...  \n",
       "2538  ['0', '0', '0', '0', '0', '1', '0', '0', '1', ...  \n",
       "2551  ['0', '0', '0', '0', '1', '0', '0', '0', '0', ...  \n",
       "2575  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...  \n",
       "\n",
       "[208 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"Davis_train.csv\")\n",
    "del_num = train_df[\"Y\"].value_counts()[0] -  train_df[\"Y\"].value_counts()[1]\n",
    "\n",
    "# df는 DataFrame의 이름이고 'column_name'은 특정 컬럼의 이름입니다.\n",
    "zero_rows = train_df[train_df['Y'] == 0].index\n",
    "drop_indices = np.random.choice(zero_rows,del_num , replace=False)\n",
    "train_df = train_df.drop(drop_indices)\n",
    "train_df\n",
    "\n",
    "val_df = pd.read_csv(\"Davis_val.csv\")\n",
    "del_num = val_df[\"Y\"].value_counts()[0] - val_df[\"Y\"].value_counts()[1]\n",
    "\n",
    "# df는 DataFrame의 이름이고 'column_name'은 특정 컬럼의 이름입니다.\n",
    "zero_rows = val_df[val_df['Y'] == 0].index\n",
    "drop_indices = np.random.choice(zero_rows,del_num , replace=False)\n",
    "val_df = val_df.drop(drop_indices)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93437f93-7fe6-418b-b66b-02ab2e9a5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Label 0,1 개수를 맞춰서 data set을 구성하여 다시 Feature 값을 구함.\n",
    "\n",
    "train_pro_table = generating_pro_feature(train_df)\n",
    "\n",
    "train_drug_table = generating_drug_feature(train_df)\n",
    "\n",
    "train_merge_on = concat_feature(train_drug_table, train_pro_table)\n",
    "\n",
    "val_pro_table = generating_pro_feature(val_df)\n",
    "\n",
    "val_drug_table = generating_drug_feature(val_df)\n",
    "\n",
    "val_merge_on = concat_feature(val_drug_table,val_pro_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a94fa23-7bb3-457f-a24b-8bbc2ea40a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Accuracy: 0.7740384615384616 F1-score 0.7661691542288558\n",
      "Train : Accuracy: 0.7603748326639893 F1-score 0.7405797101449275\n"
     ]
    }
   ],
   "source": [
    "my_SVM(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5f781-d3ea-4f2b-b5a4-04a0e263f9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "743541ce-88da-4e0d-8a94-def06a7b5b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Accuracy: 0.7590361445783133 F1-score: 0.7345132743362832\n",
      "Validation - Accuracy: 0.7692307692307693 F1-score: 0.7575757575757577\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def my_XGBoost(df_train, df_val, d_col, p_col, r_col):\n",
    "    def prepare_data(df):\n",
    "        p_feat = pd.DataFrame(df[p_col].tolist())\n",
    "        d_feat = pd.DataFrame(df[d_col].tolist()).astype(int)\n",
    "        \n",
    "        concat_feats = pd.concat([p_feat, d_feat], axis=1)\n",
    "        gt_rels = df[r_col]\n",
    "        \n",
    "        concat_feats.columns = range(concat_feats.shape[1])\n",
    "        \n",
    "        return xgb.DMatrix(concat_feats, label=gt_rels)\n",
    "    \n",
    "    dtrain = prepare_data(df_train)\n",
    "    dval = prepare_data(df_val)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': ['error', 'logloss', 'auc'],\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.1\n",
    "    }\n",
    "    \n",
    "    model = xgb.train(params, dtrain)\n",
    "    \n",
    "    def evaluate(dmatrix, gt_rels):\n",
    "        pred = model.predict(dmatrix)\n",
    "        pred_binary = [1 if p >= 0.5 else 0 for p in pred]\n",
    "        accuracy = accuracy_score(gt_rels, pred_binary)\n",
    "        f1score = f1_score(gt_rels, pred_binary)\n",
    "        return accuracy, f1score\n",
    "    \n",
    "    accuracy_train, f1score_train = evaluate(dtrain, df_train[r_col])\n",
    "    print(\"Train - Accuracy:\", accuracy_train, \"F1-score:\", f1score_train)\n",
    "    \n",
    "    accuracy_val, f1score_val = evaluate(dval, df_val[r_col])\n",
    "    print(\"Validation - Accuracy:\", accuracy_val, \"F1-score:\", f1score_val)\n",
    "\n",
    "\n",
    "my_XGBoost(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3fb85-78c7-43a5-af8f-0036bc32dfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34d013ba-e774-458f-91c6-c991f43e6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Accuracy: 0.7603748326639893 F1-score: 0.7405797101449275\n",
      "Validation - Accuracy: 0.7740384615384616 F1-score: 0.7661691542288558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def my_RandomForest(df_train, df_val, d_col, p_col, r_col):\n",
    "    def prepare_data(df):\n",
    "        p_feat = pd.DataFrame(df[d_col].tolist())\n",
    "        d_feat = pd.DataFrame(df[p_col].tolist())\n",
    "        concat_feats = pd.concat([p_feat, d_feat], axis=1)\n",
    "        gt_rels = df[r_col]\n",
    "        return concat_feats, gt_rels\n",
    "\n",
    "    X_train, y_train = prepare_data(df_train)\n",
    "    X_val, y_val = prepare_data(df_val)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    def evaluate(X, y):\n",
    "        pred = model.predict(X)\n",
    "        accuracy = accuracy_score(y, pred)\n",
    "        f1score = f1_score(y, pred)\n",
    "        return accuracy, f1score\n",
    "    \n",
    "    accuracy_train, f1score_train = evaluate(X_train, y_train)\n",
    "    print(\"Train - Accuracy:\", accuracy_train, \"F1-score:\", f1score_train)\n",
    "    \n",
    "    accuracy_val, f1score_val = evaluate(X_val, y_val)\n",
    "    print(\"Validation - Accuracy:\", accuracy_val, \"F1-score:\", f1score_val)\n",
    "\n",
    "my_RandomForest(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9362f7ff-2eca-4194-bfa3-f0188b336b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model Result\n",
      "Validation : Accuracy: 0.7740384615384616 F1-score 0.7661691542288558\n",
      "Train : Accuracy: 0.7603748326639893 F1-score 0.7405797101449275\n",
      "\n",
      "XGBoost model Result\n",
      "Train - Accuracy: 0.7590361445783133 F1-score: 0.7345132743362832\n",
      "Validation - Accuracy: 0.7692307692307693 F1-score: 0.7575757575757577\n",
      "\n",
      "RandomForest model Result\n",
      "Train - Accuracy: 0.7603748326639893 F1-score: 0.7405797101449275\n",
      "Validation - Accuracy: 0.7740384615384616 F1-score: 0.7661691542288558\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM model Result\")\n",
    "my_SVM(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")\n",
    "print()\n",
    "print(\"XGBoost model Result\")\n",
    "my_XGBoost(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")\n",
    "print()\n",
    "print(\"RandomForest model Result\")\n",
    "my_RandomForest(train_merge_on, val_merge_on,'Morgan_Features', 'ProtBERT_Features', \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83c66c-ef8b-40b9-8909-14f34fd165c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumgnn",
   "language": "python",
   "name": "sumgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
